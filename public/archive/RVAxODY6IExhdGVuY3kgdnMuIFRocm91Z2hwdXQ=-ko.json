{"title":"EP186: Latency vs. Throughput","content":"<body>\n  <h1>QA Wolf: AI 기반 테스트 자동화 솔루션</h1>\n  <p>QA Wolf는 웹 및 모바일 앱을 위한 AI 기반 테스트 자동화 솔루션을 제공하여 테스트 커버리지를 높이고 QA 주기 시간을 단축합니다. 80% 이상의 사용자 흐름 테스트 커버리지를 몇 주 안에 달성하고, 무제한 병렬 테스트 실행, 24시간 유지보수, 플레인 없는(guaranteed zero flakes) 테스트를 제공합니다.</p>\n  <p><strong>주요 혜택:</strong></p>\n  <ul>\n    <li>수동 E2E 테스트 제거</li>\n    <li>QA 주기 시간 단축</li>\n    <li>프로덕션 버그 감소</li>\n  </ul>\n  <p>Drata 팀은 QA Wolf를 통해 테스트 케이스를 4배 늘리고 QA 주기를 86% 단축하는 성과를 거두었습니다.</p>\n  <p><strong>G2 평점:</strong> 4.8/5</p>\n  <p><a href=\"#\">데모 신청하기</a></p>\n\n  <h2>이번 주 시스템 디자인 리프레셔</h2>\n  <h3>1. 지연 시간(Latency) vs. 처리량(Throughput)</h3>\n  <p><strong>지연 시간:</strong> 패킷당 지연 시간으로, 사용자가 클릭할 때 느끼는 반응성을 나타냅니다. 서버 처리, 큐잉, 네트워크 전파, 전송, 최종 사용자 연결까지의 시간을 포함합니다.</p>\n  <p><strong>처리량:</strong> 단위 시간당 데이터 전송량으로, 파이프를 통과하는 패킷의 수를 의미하며 시스템의 용량을 나타냅니다. 고처리량은 시스템이 부하를 문제없이 처리함을 의미합니다.</p>\n  <p><strong>고려 사항:</strong> 이러한 지표를 측정하여 시스템이 언제 고장 날지 예측하는 방법은 무엇인가요?</p>\n\n  <h3>2. 알아야 할 시스템 디자인 개념 20가지</h3>\n  <ul>\n    <li><strong>로드 밸런싱:</strong> 여러 서버에 트래픽을 분산하여 신뢰성과 가용성을 높입니다.</li>\n    <li><strong>캐싱:</strong> 자주 액세스하는 데이터를 메모리에 저장하여 빠른 액세스를 제공합니다.</li>\n    <li><strong>데이터베이스 샤딩:</strong> 대규모 데이터 성장을 처리하기 위해 데이터베이스를 분할합니다.</li>\n    <li><strong>복제:</strong> 가용성과 내결함성을 위해 데이터를 복제본에 복사합니다.</li>\n    <li><strong>CAP 정리:</strong> 일관성, 가용성, 분할 내성 간의 트레이드오프입니다.</li>\n    <li><strong>일관성 해싱:</strong> 동적 서버 환경에서 부하를 고르게 분산합니다.</li>\n    <li><strong>메시지 큐:</strong> 비동기 이벤트 기반 아키텍처를 사용하여 서비스를 분리합니다.</li>\n    <li><strong>속도 제한:</strong> 시스템 과부하를 방지하기 위해 요청 빈도를 제어합니다.</li>\n    <li><strong>API 게이트웨이:</strong> API 요청 라우팅을 위한 중앙 집중식 진입점입니다.</li>\n    <li><strong>마이크로서비스:</strong> 시스템을 독립적이고 느슨하게 결합된 서비스로 분할합니다.</li>\n    <li><strong>서비스 검색:</strong> 분산 시스템에서 서비스를 동적으로 찾습니다.</li>\n    <li><strong>CDN:</strong> 엣지 서버에서 콘텐츠를 제공하여 속도를 높입니다.</li>\n    <li><strong>데이터베이스 인덱싱:</strong> 중요한 필드를 인덱싱하여 쿼리를 가속화합니다.</li>\n    <li><strong>데이터 파티셔닝:</strong> 확장성 및 성능을 위해 데이터를 노드에 분할합니다.</li>\n    <li><strong>최종 일관성:</strong> 분산 데이터베이스에서 시간이 지남에 따라 일관성을 보장합니다.</li>\n    <li><strong>웹소켓:</strong> 실시간 업데이트를 위한 양방향 통신을 활성화합니다.</li>\n    <li><strong>확장성:</strong> 머신을 업그레이드하거나 추가하여 용량을 늘립니다.</li>\n    <li><strong>내결함성:</strong> 하드웨어/소프트웨어 장애 중 시스템 가용성을 보장합니다.</li>\n    <li><strong>모니터링:</strong> 시스템 상태를 이해하기 위해 메트릭과 로그를 추적합니다.</li>\n    <li><strong>인증 및 권한 부여:</strong> 사용자 액세스를 제어하고 신원을 안전하게 확인합니다.</li>\n  </ul>\n  <p><strong>고려 사항:</strong> 이 목록에 추가할 다른 시스템 디자인 개념이 있나요?</p>\n\n  <h3>3. 느린 API 디버깅 방법</h3>\n  <p><strong>네트워크 확인:</strong> 높은 지연 시간이 있다면 CDN 사용을 고려하고, 큰 페이로드는 응답 압축을 적용합니다.</p>\n  <p><strong>백엔드 코드 확인:</strong> CPU 집약적인 작업은 백그라운드에서 실행하고, 복잡한 비즈니스 로직은 단순화하며, 차단하는 동기 호출은 비동기로 변경합니다. 프로파일링을 통해 병목 구간을 찾아 수정합니다.</p>\n  <p><strong>데이터베이스 확인:</strong> 누락된 인덱스가 주요 원인일 수 있으며, N+1 쿼리(수백 번의 DB 호출 대신 단일 배치 쿼리로 처리 가능)를 주의합니다.</p>\n  <p><strong>외부 API 확인:</strong> 외부 API 호출 시 병렬 호출, 공격적인 타임아웃 및 재시도를 설정하여 하나의 느린 외부 API가 전체 응답을 저하시키지 않도록 합니다.</p>\n  <p><strong>인프라 확인:</strong> 서버 자원 부족 시 자동 확장을 적용하고, 연결 풀 제한을 조정합니다.</p>\n  <p><strong>핵심:</strong> 해결책을 무작정 적용하지 말고, 먼저 측정하여 실제 병목 현상을 파악하고 수정합니다.</p>\n  <p><strong>고려 사항:</strong> 가장 기이한 성능 문제 추적 경험이 있나요?</p>\n\n  <h3>4. LLM은 세상을 어떻게 보는가</h3>\n  <p>LLM은 텍스트를 숫자로 변환하여 처리합니다.</p>\n  <ul>\n    <li><strong>전처리:</strong> 텍스트를 정규화하고, 유니코드 문자, 공백, 특수 기호를 정리합니다.</li>\n    <li><strong>토큰화:</strong> 텍스트를 토큰으로 분할합니다.\n      <ul>\n        <li><strong>문자 기반:</strong> 각 문자를 토큰으로 만듭니다. (효율성 낮음)</li>\n        <li><strong>단어 기반:</strong> 전체 단어를 토큰으로 만듭니다. (희귀 단어 처리 어려움)</li>\n        <li><strong>부분 단어 기반(Subword-based):</strong> 현대 LLM에서 사용하며, 효율성과 유연성을 균형 있게 맞춥니다. (예: \"Hello world\" -> [\"Hell\", \"o\", \"world\"])</li>\n      </ul>\n    </li>\n    <li><strong>토큰 ID:</strong> 부분 단어가 숫자로 매핑됩니다. (예: [\"Hell\", \"o\", \"world\"] -> [15496, 345, 995]) 이 토큰 ID가 모델이 처리하는 임베딩 벡터에 해당합니다.</li>\n  </ul>\n  <p><strong>고려 사항:</strong> 일부 모델이 자연어보다 코드를 더 잘 처리하는 이유는 무엇이며, 토크나이저가 관련이 있나요?</p>\n\n  <h3>5. RAG vs. 파인튜닝(Fine-tuning): 무엇을 사용해야 할까?</h3>\n  <p>LLM을 새로운 작업에 적응시키는 두 가지 주요 접근 방식입니다.</p>\n  <ul>\n    <li><strong>RAG (Retrieval-Augmented Generation):</strong> 런타임에 외부 소스(문서, DB, API)에서 지식을 가져옵니다. 유연하고 항상 최신 정보를 유지합니다.</li>\n    <li><strong>파인튜닝:</strong> 오프라인 학습을 통해 도메인별 데이터로 모델 가중치를 업데이트하여 해당 분야의 전문가로 만듭니다.</li>\n  </ul>\n  <p><strong>고려 사항:</strong> 귀하의 도메인에서는 최신 지식(RAG)이 더 가치 있나요, 아니면 내재된 전문성(파인튜닝)이 더 가치 있나요?</p>\n\n  <h2>스폰서십</h2>\n  <p>100만 명 이상의 기술 전문가에게 제품을 노출하세요. 수십만 명의 엔지니어링 리더 및 시니어 엔지니어를 대상으로 제품과 서비스를 직접 선보일 수 있습니다. 광고 공간은 빠르게 채워지므로, sponsorship@bytebytego.com으로 문의하여 지금 예약하세요.</p>\n</body>","createdAt":"2025-10-25T15:31:00.000+00:00","link":"https://blog.bytebytego.com/p/ep186-latency-vs-throughput","language":"ko"}